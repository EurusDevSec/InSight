"""
Kiá»ƒm tra tÃ­nh toÃ n váº¹n cá»§a dataset
Cháº¡y: python scripts/validate_dataset.py [--path <path_to_ground_truth>]
"""

import json
import argparse
from pathlib import Path


def validate_dataset(gt_path: str = "data/annotations/ground_truth.json"):
    errors = []
    warnings = []

    # Load ground truth
    gt_file = Path(gt_path)
    if not gt_file.exists():
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y {gt_path}")
        return False

    with open(gt_file, "r", encoding="utf-8") as f:
        data = json.load(f)

    samples = data["samples"]
    base_dir = gt_file.parent.parent  # data/poc/ hoáº·c data/

    print(f"ğŸ“Š Kiá»ƒm tra {len(samples)} máº«u tá»« {gt_path}...\n")

    # Thá»‘ng kÃª theo category
    categories = {}

    for sample in samples:
        sample_id = sample["id"]
        category = sample.get("food_category", "unknown")
        categories[category] = categories.get(category, 0) + 1

        # 1. Kiá»ƒm tra áº£nh tá»“n táº¡i
        img_path = base_dir / sample["image_file"]
        if not img_path.exists():
            errors.append(f"[{sample_id}] Thiáº¿u áº£nh: {img_path}")

        # 2. Kiá»ƒm tra ground truth há»£p lá»‡
        gt = sample["ground_truth"]
        if gt["total_weight_g"] <= 0:
            errors.append(f"[{sample_id}] Trá»ng lÆ°á»£ng <= 0")

        if gt["is_liquid"] and gt["liquid_volume_ml"] <= 0:
            warnings.append(f"[{sample_id}] MÃ³n nÆ°á»›c nhÆ°ng khÃ´ng cÃ³ thá»ƒ tÃ­ch nÆ°á»›c")

        # 3. Kiá»ƒm tra metadata
        if not sample["metadata"].get("restaurant"):
            warnings.append(f"[{sample_id}] Thiáº¿u thÃ´ng tin quÃ¡n")

        # 4. Kiá»ƒm tra image file extension
        img_file = sample["image_file"]
        if not img_file.lower().endswith((".jpg", ".jpeg", ".png")):
            warnings.append(f"[{sample_id}] File khÃ´ng pháº£i áº£nh: {img_file}")

    # Report
    print("=" * 50)

    # Thá»‘ng kÃª category
    print("ğŸ“Š Thá»‘ng kÃª theo loáº¡i:")
    for cat, count in sorted(categories.items()):
        print(f"   - {cat}: {count} máº«u")
    print()

    if errors:
        print(f"âŒ {len(errors)} Lá»–I:")
        for e in errors:
            print(f"   - {e}")
    else:
        print("âœ… KhÃ´ng cÃ³ lá»—i nghiÃªm trá»ng!")

    if warnings:
        print(f"\nâš ï¸  {len(warnings)} Cáº¢NH BÃO:")
        for w in warnings:
            print(f"   - {w}")

    print("=" * 50)
    valid = len(samples) - len(errors)
    print(f"ğŸ“ˆ Káº¿t quáº£: {valid}/{len(samples)} máº«u há»£p lá»‡")

    return len(errors) == 0


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Validate InSight dataset")
    parser.add_argument(
        "--path",
        default="data/annotations/ground_truth.json",
        help="Path to ground_truth.json",
    )
    args = parser.parse_args()

    success = validate_dataset(args.path)
    exit(0 if success else 1)
